{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a30e11d-6753-48b5-b763-5c2f5a8e0056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install prophet lightgbm prefect --no-deps --quiet\n",
    "%pip install -U opentelemetry-api --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d55a3f3-56d4-4e17-916c-467fefe912ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Workspace/Repos/desareca/santiago-weather-forecast\")\n",
    "\n",
    "from src.data.ingestion import load_from_delta_table\n",
    "from src.data.preprocessing import prepare_time_series, train_test_split_temporal\n",
    "from src.models.arima_model import ARIMAPredictor\n",
    "from src.models.prophet_model import ProphetPredictor\n",
    "from src.evaluation.cross_validation import TimeSeriesSplit, evaluate_with_cv\n",
    "from src.utils.config import *\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar experimento MLflow\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(\"‚úÖ Setup completo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68951655-0a02-4615-aa67-6489bcbeafd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar datos desde Delta Table\n",
    "df = load_from_delta_table(\"weather_raw\", spark)\n",
    "\n",
    "# Preparar serie temporal\n",
    "serie = prepare_time_series(df, target_col=\"precipitacion\")\n",
    "\n",
    "# Train/Test split tradicional (80/20)\n",
    "train, test = train_test_split_temporal(serie, train_ratio=TRAIN_SPLIT)\n",
    "\n",
    "print(f\"\\nüìä Datos preparados:\")\n",
    "print(f\"  Serie completa: {len(serie)} d√≠as\")\n",
    "print(f\"  Train: {len(train)} d√≠as\")\n",
    "print(f\"  Test: {len(test)} d√≠as\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fee6bbe-a7cf-48a5-b173-4de3f843d8c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENTO 1: ARIMA(1,1,1) Baseline\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear y entrenar modelo ARIMA\n",
    "arima_baseline = ARIMAPredictor(p=1, d=1, q=1)\n",
    "\n",
    "# Entrenar y evaluar con MLflow tracking\n",
    "metrics_arima = arima_baseline.train_and_evaluate(train, test, log_mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2f7db2-73e8-426d-ba3c-2641c7ace80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENTO 2: Prophet con estacionalidad anual\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear y entrenar modelo Prophet\n",
    "prophet_model = ProphetPredictor(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    changepoint_prior_scale=0.05\n",
    ")\n",
    "\n",
    "# Entrenar y evaluar con MLflow tracking\n",
    "metrics_prophet = prophet_model.train_and_evaluate(train, test, log_mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c229f481-0294-4bf9-8784-6a7d431aa449",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACI√ìN INICIAL (Train/Test Split)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ver qu√© m√©tricas retorn√≥ cada modelo\n",
    "print(\"\\nM√©tricas disponibles ARIMA:\")\n",
    "print(metrics_arima.keys())\n",
    "print(\"\\nM√©tricas disponibles Prophet:\")\n",
    "print(metrics_prophet.keys())\n",
    "\n",
    "# Comparaci√≥n\n",
    "comparison_simple = pd.DataFrame({\n",
    "    'ARIMA(1,1,1)': pd.Series(metrics_arima),\n",
    "    'Prophet': pd.Series(metrics_prophet)\n",
    "})\n",
    "\n",
    "print(\"\\nüìä Todas las m√©tricas:\")\n",
    "print(comparison_simple.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96ae1b61-f539-4936-9bb3-c11002a9d8c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION: Visualizaci√≥n de Folds\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Crear objeto CV\n",
    "cv = TimeSeriesSplit(n_splits=5, test_size=30)\n",
    "\n",
    "# Visualizar splits\n",
    "cv.visualize_splits(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e94d14d-ca6a-4253-bafb-99e0ed8e83bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION: ARIMA(1,1,1)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_arima_cv = evaluate_with_cv(\n",
    "    model_class=ARIMAPredictor,\n",
    "    data=serie,\n",
    "    n_splits=5,\n",
    "    p=1, d=1, q=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9859ce-a7fa-465d-8c82-7b6760a86545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION: Prophet\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_prophet_cv = evaluate_with_cv(\n",
    "    model_class=ProphetPredictor,\n",
    "    data=serie,\n",
    "    n_splits=5,\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=False,\n",
    "    changepoint_prior_scale=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "899f5962-d7f8-410a-8631-833f8a853b45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACI√ìN FINAL (Promedios Cross-Validation)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Comparar promedios de ambos modelos\n",
    "comparison_cv = pd.DataFrame({\n",
    "    'ARIMA': results_arima_cv[['mae', 'rmse', 'r2', 'accuracy', 'precision', 'recall', 'f1_score']].mean(),\n",
    "    'Prophet': results_prophet_cv[['mae', 'rmse', 'r2', 'accuracy', 'precision', 'recall', 'f1_score']].mean()\n",
    "})\n",
    "\n",
    "print(comparison_cv.round(3))\n",
    "\n",
    "# Ganadores por m√©trica\n",
    "print(\"\\nüèÜ Ganadores por m√©trica:\")\n",
    "for metric in ['mae', 'rmse', 'r2', 'accuracy', 'f1_score']:\n",
    "    if metric in ['r2', 'accuracy', 'f1_score']:  # Mayor es mejor\n",
    "        winner = comparison_cv.loc[metric].idxmax()\n",
    "        value = comparison_cv.loc[metric].max()\n",
    "    else:  # Menor es mejor (MAE, RMSE)\n",
    "        winner = comparison_cv.loc[metric].idxmin()\n",
    "        value = comparison_cv.loc[metric].min()\n",
    "    \n",
    "    print(f\"  {metric.upper():12s}: {winner:10s} ({value:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_model_experiments",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
