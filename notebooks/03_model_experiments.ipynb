{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a30e11d-6753-48b5-b763-5c2f5a8e0056",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install prophet lightgbm prefect holidays tqdm --no-deps --quiet\n",
    "%pip install -U opentelemetry-api --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c21e6d53-980f-4249-8c26-92c333b669a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import sys\n",
    "sys.path.append(\"/Workspace/Repos/desareca/santiago-weather-forecast\")\n",
    "\n",
    "from src.data.ingestion import load_from_delta_table\n",
    "from src.data.preprocessing import prepare_time_series\n",
    "from src.models.arima_model import ARIMAPredictor\n",
    "from src.models.prophet_model import ProphetPredictor\n",
    "from src.models.lightgbm_model import LightGBMPredictor\n",
    "from src.evaluation.cross_validation import TimeSeriesSplit\n",
    "from src.utils.config import *\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "print(\"‚úÖ Setup completo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1674a823-6403-4854-8777-20954ae8fd43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cargar y preparar datos\n",
    "df = load_from_delta_table(\"weather_raw\", spark)\n",
    "serie = prepare_time_series(df, target_col=\"precipitacion\")\n",
    "\n",
    "print(f\"\\nüìä Datos preparados:\")\n",
    "print(f\"  Serie completa: {len(serie)} d√≠as\")\n",
    "print(f\"  Fecha inicio: {serie.index.min().date()}\")\n",
    "print(f\"  Fecha fin: {serie.index.max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d13d4041-17ea-4fe1-84a0-bf74d4fe2b3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VISUALIZACI√ìN DE FOLDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5, test_size=30)\n",
    "cv.visualize_splits(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc7f7e7e-e059-4a7e-8583-a826bf2eb181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GRID SEARCH: ARIMA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Grilla de hiperpar√°metros ARIMA\n",
    "arima_grid = [\n",
    "    # Modelos simples\n",
    "    {'p': 1, 'd': 0, 'q': 0, 'name': 'AR(1)'},\n",
    "    {'p': 0, 'd': 0, 'q': 1, 'name': 'MA(1)'},\n",
    "    {'p': 1, 'd': 1, 'q': 0, 'name': 'ARIMA(1,1,0)'},\n",
    "    {'p': 0, 'd': 1, 'q': 1, 'name': 'ARIMA(0,1,1)'},\n",
    "    {'p': 1, 'd': 1, 'q': 1, 'name': 'ARIMA(1,1,1) - Baseline'},\n",
    "    \n",
    "    # Modelos con m√°s lags\n",
    "    {'p': 2, 'd': 1, 'q': 1, 'name': 'ARIMA(2,1,1)'},\n",
    "    {'p': 1, 'd': 1, 'q': 2, 'name': 'ARIMA(1,1,2)'},\n",
    "    {'p': 2, 'd': 1, 'q': 2, 'name': 'ARIMA(2,1,2)'},\n",
    "    \n",
    "    # Modelos estacionales (pensando en ciclo anual)\n",
    "    {'p': 1, 'd': 0, 'q': 1, 'name': 'ARMA(1,1) - Sin diferenciaci√≥n'},\n",
    "    {'p': 3, 'd': 1, 'q': 1, 'name': 'ARIMA(3,1,1)'},\n",
    "    {'p': 1, 'd': 1, 'q': 3, 'name': 'ARIMA(1,1,3)'},\n",
    "    \n",
    "    # Modelos m√°s complejos\n",
    "    {'p': 2, 'd': 2, 'q': 2, 'name': 'ARIMA(2,2,2) - Dos diferenciaciones'},\n",
    "    {'p': 3, 'd': 1, 'q': 3, 'name': 'ARIMA(3,1,3)'},\n",
    "]\n",
    "\n",
    "# Entrenar todos\n",
    "results_arima_grid = []\n",
    "\n",
    "for i, params in enumerate(arima_grid):\n",
    "    print(f\"\\n[{i+1}/{len(arima_grid)}] Probando {params['name']}...\")\n",
    "    \n",
    "    arima = ARIMAPredictor(p=params['p'], d=params['d'], q=params['q'])\n",
    "    \n",
    "    try:\n",
    "        results_cv = arima.train_and_evaluate_cv(\n",
    "            data=serie,\n",
    "            n_splits=5,\n",
    "            test_size=30,\n",
    "            log_mlflow=True,\n",
    "            run_description=f\"ARIMA Grid Search - {params['name']}\"\n",
    "        )\n",
    "        \n",
    "        avg_metrics = results_cv[['mae', 'rmse', 'r2', 'f1_score']].mean()\n",
    "        \n",
    "        results_arima_grid.append({\n",
    "            'model': params['name'],\n",
    "            'p': params['p'],\n",
    "            'd': params['d'],\n",
    "            'q': params['q'],\n",
    "            'mae': avg_metrics['mae'],\n",
    "            'rmse': avg_metrics['rmse'],\n",
    "            'r2': avg_metrics['r2'],\n",
    "            'f1_score': avg_metrics['f1_score']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Resumen\n",
    "df_arima_grid = pd.DataFrame(results_arima_grid)\n",
    "df_arima_grid = df_arima_grid.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS GRID SEARCH ARIMA\")\n",
    "print(\"=\"*70)\n",
    "print(df_arima_grid.to_string(index=False))\n",
    "print(f\"\\nüèÜ Mejor ARIMA: {df_arima_grid.iloc[0]['model']} (F1={df_arima_grid.iloc[0]['f1_score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c376c7a6-1da0-461a-a851-b335cf6c2882",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GRID SEARCH: Prophet\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Grilla de hiperpar√°metros Prophet\n",
    "prophet_grid = [\n",
    "    # Variaciones de estacionalidad\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.05,\n",
    "        'seasonality_prior_scale': 10.0,\n",
    "        'name': 'Prophet - Solo anual (baseline)'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': True,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.05,\n",
    "        'seasonality_prior_scale': 10.0,\n",
    "        'name': 'Prophet - Anual + Semanal'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.01,  # Menos flexible\n",
    "        'seasonality_prior_scale': 10.0,\n",
    "        'name': 'Prophet - Conservador'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.1,  # M√°s flexible\n",
    "        'seasonality_prior_scale': 10.0,\n",
    "        'name': 'Prophet - Flexible'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.5,  # Muy flexible\n",
    "        'seasonality_prior_scale': 10.0,\n",
    "        'name': 'Prophet - Muy flexible'\n",
    "    },\n",
    "    \n",
    "    # Variaciones de prior de estacionalidad\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.05,\n",
    "        'seasonality_prior_scale': 1.0,  # Estacionalidad d√©bil\n",
    "        'name': 'Prophet - Estacionalidad d√©bil'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.05,\n",
    "        'seasonality_prior_scale': 20.0,  # Estacionalidad fuerte\n",
    "        'name': 'Prophet - Estacionalidad fuerte'\n",
    "    },\n",
    "    \n",
    "    # Combinaciones\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': True,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.1,\n",
    "        'seasonality_prior_scale': 15.0,\n",
    "        'name': 'Prophet - Flexible + Semanal'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.001,  # Muy r√≠gido\n",
    "        'seasonality_prior_scale': 5.0,\n",
    "        'name': 'Prophet - Muy conservador'\n",
    "    },\n",
    "    {\n",
    "        'yearly_seasonality': True,\n",
    "        'weekly_seasonality': True,\n",
    "        'daily_seasonality': False,\n",
    "        'changepoint_prior_scale': 0.2,\n",
    "        'seasonality_prior_scale': 20.0,\n",
    "        'name': 'Prophet - M√°xima flexibilidad'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Entrenar todos\n",
    "results_prophet_grid = []\n",
    "\n",
    "for i, params in enumerate(prophet_grid):\n",
    "    print(f\"\\n[{i+1}/{len(prophet_grid)}] Probando {params['name']}...\")\n",
    "    \n",
    "    prophet_model = ProphetPredictor(\n",
    "        yearly_seasonality=params['yearly_seasonality'],\n",
    "        weekly_seasonality=params['weekly_seasonality'],\n",
    "        daily_seasonality=params['daily_seasonality'],\n",
    "        changepoint_prior_scale=params['changepoint_prior_scale'],\n",
    "        seasonality_prior_scale=params['seasonality_prior_scale']\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        results_cv = prophet_model.train_and_evaluate_cv(\n",
    "            data=serie,\n",
    "            n_splits=5,\n",
    "            test_size=30,\n",
    "            log_mlflow=True,\n",
    "            run_description=f\"Prophet Grid Search - {params['name']}\"\n",
    "        )\n",
    "\n",
    "        avg_metrics = results_cv[['mae', 'rmse', 'r2', 'f1_score']].mean()\n",
    "        \n",
    "        results_prophet_grid.append({\n",
    "            'model': params['name'],\n",
    "            'yearly': params['yearly_seasonality'],\n",
    "            'weekly': params['weekly_seasonality'],\n",
    "            'cp_scale': params['changepoint_prior_scale'],\n",
    "            'season_scale': params['seasonality_prior_scale'],\n",
    "            'mae': avg_metrics['mae'],\n",
    "            'rmse': avg_metrics['rmse'],\n",
    "            'r2': avg_metrics['r2'],\n",
    "            'f1_score': avg_metrics['f1_score']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Resumen\n",
    "df_prophet_grid = pd.DataFrame(results_prophet_grid)\n",
    "df_prophet_grid = df_prophet_grid.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS GRID SEARCH PROPHET\")\n",
    "print(\"=\"*70)\n",
    "print(df_prophet_grid[['model', 'mae', 'rmse', 'r2', 'f1_score']].to_string(index=False))\n",
    "print(f\"\\nüèÜ Mejor Prophet: {df_prophet_grid.iloc[0]['model']} (F1={df_prophet_grid.iloc[0]['f1_score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc1b159a-1c8d-4535-92b0-6b6fc2f39b7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION: LightGBM - Grid Search\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Grilla de hiperpar√°metros LightGBM\n",
    "lightgbm_grid = [\n",
    "    # Baseline simple\n",
    "    {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': 'Baseline'\n",
    "    },\n",
    "    \n",
    "    # M√°s √°rboles, learning rate bajo\n",
    "    {\n",
    "        'n_estimators': 200,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': 'M√°s √°rboles (200)'\n",
    "    },\n",
    "    \n",
    "    # √Årboles profundos\n",
    "    {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 10,\n",
    "        'num_leaves': 63,\n",
    "        'min_child_samples': 10,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': '√Årboles profundos'\n",
    "    },\n",
    "    \n",
    "    # Conservador (menos overfitting)\n",
    "    {\n",
    "        'n_estimators': 150,\n",
    "        'learning_rate': 0.08,\n",
    "        'max_depth': 3,\n",
    "        'num_leaves': 15,\n",
    "        'min_child_samples': 30,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': 'Conservador'\n",
    "    },\n",
    "    \n",
    "    # Con regularizaci√≥n L1\n",
    "    {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 1.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': 'Regularizaci√≥n L1'\n",
    "    },\n",
    "    \n",
    "    # Con regularizaci√≥n L2\n",
    "    {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 1.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': 'Regularizaci√≥n L2'\n",
    "    },\n",
    "    \n",
    "    # M√°s lags\n",
    "    {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 2, 3, 7, 14, 30],\n",
    "        'rolling_windows': [7, 14, 30],\n",
    "        'name': 'M√°s lags (6)'\n",
    "    },\n",
    "    \n",
    "    # Subsample bajo\n",
    "    {\n",
    "        'n_estimators': 150,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 20,\n",
    "        'subsample': 0.5,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'reg_alpha': 0.0,\n",
    "        'reg_lambda': 0.0,\n",
    "        'lags': [1, 7, 30],\n",
    "        'rolling_windows': [7, 30],\n",
    "        'name': 'Subsample bajo'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Entrenar todos\n",
    "results_lgbm_grid = []\n",
    "\n",
    "for i, params in enumerate(lightgbm_grid):\n",
    "    print(f\"\\n[{i+1}/{len(lightgbm_grid)}] Probando LightGBM - {params['name']}...\")\n",
    "    \n",
    "    lgbm = LightGBMPredictor(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        max_depth=params['max_depth'],\n",
    "        num_leaves=params['num_leaves'],\n",
    "        min_child_samples=params['min_child_samples'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        reg_alpha=params['reg_alpha'],\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        lags=params['lags'],\n",
    "        rolling_windows=params['rolling_windows']\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        results_cv = lgbm.train_and_evaluate_cv(\n",
    "            data=serie,\n",
    "            n_splits=5,\n",
    "            test_size=30,\n",
    "            log_mlflow=True,\n",
    "            run_description=f\"LightGBM Grid Search - {params['name']}\"\n",
    "        )\n",
    "        \n",
    "        avg_metrics = results_cv[['mae', 'rmse', 'r2', 'f1_score']].mean()\n",
    "        \n",
    "        results_lgbm_grid.append({\n",
    "            'model': params['name'],\n",
    "            'n_estimators': params['n_estimators'],\n",
    "            'learning_rate': params['learning_rate'],\n",
    "            'max_depth': params['max_depth'],\n",
    "            'n_lags': len(params['lags']),\n",
    "            'mae': avg_metrics['mae'],\n",
    "            'rmse': avg_metrics['rmse'],\n",
    "            'r2': avg_metrics['r2'],\n",
    "            'f1_score': avg_metrics['f1_score']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è  Error: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Resumen\n",
    "df_lgbm_grid = pd.DataFrame(results_lgbm_grid)\n",
    "df_lgbm_grid = df_lgbm_grid.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTADOS GRID SEARCH LIGHTGBM\")\n",
    "print(\"=\"*70)\n",
    "print(df_lgbm_grid[['model', 'mae', 'rmse', 'r2', 'f1_score']].to_string(index=False))\n",
    "print(f\"\\nüèÜ Mejor LightGBM: {df_lgbm_grid.iloc[0]['model']} (F1={df_lgbm_grid.iloc[0]['f1_score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f93398-5bc1-4710-8619-8ddacef9bfe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACI√ìN FINAL: MEJOR ARIMA vs MEJOR PROPHET vs MEJOR LIGHTGBM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_arima = df_arima_grid.iloc[0]\n",
    "best_prophet = df_prophet_grid.iloc[0]\n",
    "best_lgbm = df_lgbm_grid.iloc[0]\n",
    "\n",
    "comparison_final = pd.DataFrame({\n",
    "    'ARIMA': [best_arima['mae'], best_arima['rmse'], best_arima['r2'], best_arima['f1_score']],\n",
    "    'Prophet': [best_prophet['mae'], best_prophet['rmse'], best_prophet['r2'], best_prophet['f1_score']],\n",
    "    'LightGBM': [best_lgbm['mae'], best_lgbm['rmse'], best_lgbm['r2'], best_lgbm['f1_score']]\n",
    "}, index=['MAE', 'RMSE', 'R¬≤', 'F1-Score'])\n",
    "\n",
    "print(\"\\nüìä Mejores modelos de cada familia:\")\n",
    "print(comparison_final.round(3))\n",
    "\n",
    "print(f\"\\nü•á Mejor ARIMA: {best_arima['model']}\")\n",
    "print(f\"   p={best_arima['p']}, d={best_arima['d']}, q={best_arima['q']}\")\n",
    "\n",
    "print(f\"\\nü•á Mejor Prophet: {best_prophet['model']}\")\n",
    "print(f\"   changepoint_prior_scale={best_prophet['cp_scale']}\")\n",
    "print(f\"   seasonality_prior_scale={best_prophet['season_scale']}\")\n",
    "\n",
    "print(f\"\\nü•á Mejor LightGBM: {best_lgbm['model']}\")\n",
    "print(f\"   n_estimators={best_lgbm['n_estimators']}\")\n",
    "print(f\"   learning_rate={best_lgbm['learning_rate']}\")\n",
    "print(f\"   max_depth={best_lgbm['max_depth']}\")\n",
    "print(f\"   n_lags={best_lgbm['n_lags']}\")\n",
    "\n",
    "# Ganador absoluto\n",
    "winner_scores = {\n",
    "    'ARIMA': best_arima['f1_score'],\n",
    "    'Prophet': best_prophet['f1_score'],\n",
    "    'LightGBM': best_lgbm['f1_score']\n",
    "}\n",
    "\n",
    "champion = max(winner_scores, key=winner_scores.get)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üèÜ CAMPE√ìN ABSOLUTO: {champion}\")\n",
    "print(f\"{'='*70}\")\n",
    "if champion == 'ARIMA':\n",
    "    print(f\"   Configuraci√≥n: {best_arima['model']}\")\n",
    "    print(f\"   F1-Score: {best_arima['f1_score']:.3f}\")\n",
    "    print(f\"   Par√°metros: p={best_arima['p']}, d={best_arima['d']}, q={best_arima['q']}\")\n",
    "elif champion == 'Prophet':\n",
    "    print(f\"   Configuraci√≥n: {best_prophet['model']}\")\n",
    "    print(f\"   F1-Score: {best_prophet['f1_score']:.3f}\")\n",
    "    print(f\"   changepoint_prior_scale={best_prophet['cp_scale']}\")\n",
    "    print(f\"   seasonality_prior_scale={best_prophet['season_scale']}\")\n",
    "else:  # LightGBM\n",
    "    print(f\"   Configuraci√≥n: {best_lgbm['model']}\")\n",
    "    print(f\"   F1-Score: {best_lgbm['f1_score']:.3f}\")\n",
    "    print(f\"   n_estimators={best_lgbm['n_estimators']}, lr={best_lgbm['learning_rate']}, depth={best_lgbm['max_depth']}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_model_experiments",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
